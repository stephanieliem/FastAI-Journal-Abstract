{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Group51 Model Script.ipynb","provenance":[{"file_id":"1WhvmdDcSwSyOU9bLdl9vYR4Vhe3jAnvy","timestamp":1604524337706},{"file_id":"1D-V3KmPEItwWJoD7ojXMcJiVD2Iob6U1","timestamp":1604492441969}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"07069ce96d3f40339a6484b5fb733b77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_304f08ff2e6741c39d424d3301918aee","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f2bf93e070a5403d83d6623d73bcd499","IPY_MODEL_86ed3f720f6f4585ade5315cc8a1d458"]}},"304f08ff2e6741c39d424d3301918aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2bf93e070a5403d83d6623d73bcd499":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec796c5b8acc45709e48d51168e859b0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":29638,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29638,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32556fbc3d014efe8e823172504c99d4"}},"86ed3f720f6f4585ade5315cc8a1d458":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6ad89958a8a446a982aed19cb13d35d9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29638/29638 [08:41&lt;00:00, 56.87it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44b58a73bdc441b6ae06f63187f28372"}},"ec796c5b8acc45709e48d51168e859b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"32556fbc3d014efe8e823172504c99d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ad89958a8a446a982aed19cb13d35d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"44b58a73bdc441b6ae06f63187f28372":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8272a0204ebb4ca482d52ab2c9175cd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ac4ffeaf80947668ba489855852fa25","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72d9bbf42a1347ecbeaaa387424d7d97","IPY_MODEL_e58f96c4fd2f4e8a993f6b8dbf82761f"]}},"6ac4ffeaf80947668ba489855852fa25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72d9bbf42a1347ecbeaaa387424d7d97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b4a86904bd04257925f57677c06c872","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":7410,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7410,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23db9e67e4004e5193fd0236359f9094"}},"e58f96c4fd2f4e8a993f6b8dbf82761f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f3f432c5d43437d9f1f5424e9337627","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7410/7410 [02:14&lt;00:00, 55.07it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7902310a3b34ea99df4bb87e856a643"}},"4b4a86904bd04257925f57677c06c872":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"23db9e67e4004e5193fd0236359f9094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f3f432c5d43437d9f1f5424e9337627":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7902310a3b34ea99df4bb87e856a643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"M_W8qLtynJJ3"},"source":["# FIT5149 S2 2020 \n","# Assessment 2: Predicting Journal Article Classifications\n","#### Authored and submitted by Group 51\n","\n","Programming Language: Python 3.6.9 in Google Colaboratory\n","\n","Python Libraries used:\n","- google.colab (1.0.0)\n","- fastai (2.0.18)\n","- numpy (1.18.5)\n","- random (included in python distribution)\n","- os (included in python distribution)\n","- pandas (1.1.4)\n","- nltk (3.2.5)\n","- re (included in python distribution)\n","- string (included in python distribution)\n","- tqdm (included in python distribution)"]},{"cell_type":"markdown","metadata":{"id":"c7e9a_xmfec9"},"source":["**Section 1.**\n","\n","Setting directory locations"]},{"cell_type":"code","metadata":{"id":"C-XWEpZSg2Xs","executionInfo":{"status":"ok","timestamp":1604631774768,"user_tz":-420,"elapsed":2434,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Set Working Directory\n","\n","###SET WORKING DIRECTORY DETAILS BELOW. CONSULT README FOR MORE INFORMATION\n","# Set drive location to the location of this file. e.g drive_location = 'my drive/submission'\n","drive_selection = 'My Drive/'#'Shared drives/'FIT5149 Assignment 2/'#By default, the code links to your personal drive, adjust this variable to link to sahred drives instead.\n","drive_location = 'Group 51 Assignment2 Submission'#By defaul, the distribution is assumed to be located on at the top level of your Google Drive folder structure. Adjust this varibale to point to another lcoation.\n","###\n","\n","mount_location = '/content/drive/'\n","home_directory = mount_location + drive_selection + drive_location\n","\n","data_directory = '/data'\n","language_directory = '/language models'\n","model_directory = '/models'\n","output_directory = '/model output'\n","\n","#Declare the source data\n","train_file = '/train_data_labels.csv'\n","test_file = '/test_data.csv'"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OLGxxEVpfmqw"},"source":["**Section 2**\n","\n","Mount Google Drive File System, install required package versions and import required packages."]},{"cell_type":"code","metadata":{"id":"GP4jd5xaiKm4","executionInfo":{"status":"ok","timestamp":1604631795759,"user_tz":-420,"elapsed":23411,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"e2fee42b-1926-4a78-b673-f3a2bf0d98f7","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Import the google.colab package to mount the google drive.\n","from google.colab import drive\n","\n","#Mount google drive to make the share drive content available.\n","drive.mount(mount_location)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gz_NInKBg7w1","executionInfo":{"status":"ok","timestamp":1604631796468,"user_tz":-420,"elapsed":24117,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Import required packages\n","import numpy as np\n","import random\n","import os\n","import pandas as pd\n","import nltk\n","import re\n","import string\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from tqdm import notebook"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYSJxIn6ieSN","executionInfo":{"status":"ok","timestamp":1604631798481,"user_tz":-420,"elapsed":8315,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"4cc9bc02-5bde-4a44-a9a0-5d9a156546c6","colab":{"base_uri":"https://localhost:8080/"}},"source":["import nltk\n","nltk.download('stopwords')# Download the english stopwords for use in the data cleaning\n","nltk.download('averaged_perceptron_tagger')# Download the perceptron tag data for use in pre-processing step prior to lemmatization\n","nltk.download('wordnet')# Download the wordnet data for lemmatization"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ZzZMzWja1KzL","executionInfo":{"status":"ok","timestamp":1604631940920,"user_tz":-420,"elapsed":149441,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"a25b1fb5-a388-40e7-c2ab-057c82fcceb2","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Install torch and torchvision to the below specified versions.\n","!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.6.0+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n","\u001b[K     |████████████████████████████████| 708.0MB 25kB/s \n","\u001b[?25hCollecting torchvision==0.7.0+cu101\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n","\u001b[K     |████████████████████████████████| 5.9MB 12.8MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.18.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bCgKYzIS9RsV","executionInfo":{"status":"ok","timestamp":1604631951021,"user_tz":-420,"elapsed":157643,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"df50dc57-3b5f-4b35-dbd6-35d1678e777a","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Install fatai and fastcore to the below specified versions.\n","!pip install fastai==2.0.16 fastcore==1.2.5\n","\n","#Import required packages\n","from fastai.text.all import *"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting fastai==2.0.16\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/d9/23222f694d28a6bd798f1c0f3600efd31c623ba63115c11d8fd83c83216e/fastai-2.0.16-py3-none-any.whl (187kB)\n","\u001b[K     |████████████████████████████████| 194kB 4.1MB/s \n","\u001b[?25hCollecting fastcore==1.2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/25/3ed10399c2197c4a5d0615ca0c39b2e034bbe5b99bee8217ceb61db571db/fastcore-1.2.5-py3-none-any.whl (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (0.22.2.post1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (20.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (1.1.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (3.13)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (7.0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (3.2.2)\n","Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (19.3.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (1.4.1)\n","Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (0.7.0+cu101)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (2.23.0)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (2.2.4)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (1.6.0+cu101)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai==2.0.16) (1.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai==2.0.16) (0.17.0)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai==2.0.16) (1.18.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==2.0.16) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==2.0.16) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==2.0.16) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==2.0.16) (2018.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.0.16) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==2.0.16) (1.3.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.16) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.16) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.16) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==2.0.16) (1.24.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (4.41.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (2.0.4)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (0.4.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (0.8.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (1.0.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (7.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (50.3.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (1.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (1.0.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==2.0.16) (3.0.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai==2.0.16) (0.16.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.16) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==2.0.16) (3.4.0)\n","Installing collected packages: fastcore, fastai\n","  Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","Successfully installed fastai-2.0.16 fastcore-1.2.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ghfq4J2f08J"},"source":["**Section 3**\n","\n","Define and call a seeding funciton that will ensure reproducability."]},{"cell_type":"code","metadata":{"id":"xK7hH4Tl8_JH","executionInfo":{"status":"ok","timestamp":1604631951025,"user_tz":-420,"elapsed":145959,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"67447213-c7b5-4bc2-a2af-7d50c26e931a","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Configure seed settings for all variables to ensure reproducability\n","def reset_seed():\n","  seed = 444\n","\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  os.environ['PYTHONHASHSEED'] = str(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","\n","  #Adjust the torch backend parameters to avoid the use of non-deterministic algorithms for reproducability.\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","\n","  print('Seed reset to value ', seed)\n","\n","#Set the seed value.\n","reset_seed()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Seed reset to value  333\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"naPaKMt9f8-d"},"source":["**Section 4**\n","\n","Commence Text pre-processing and cleaning."]},{"cell_type":"code","metadata":{"id":"HMbWbJq1gtnv","executionInfo":{"status":"ok","timestamp":1604631951026,"user_tz":-420,"elapsed":143927,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["stopwords = set(stopwords.words('english'))#Load stopwords into a set to improve speed on repeated calls."],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbUwREQjhbBv","executionInfo":{"status":"ok","timestamp":1604631951027,"user_tz":-420,"elapsed":143438,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Define a class that will manage the cleaning process.\n","#The text_processor class will take test or train data as an input,\n","#Perfrom all neccesary cleaning steps,\n","#Perform lemmatization\n","#And return processed data to calling functions.\n","\n","class text_processor():\n","    def __init__(self):\n","        #Decalre global variables for formating and function use.\n","        self.line_break = '\\n---------------'\n","        print(self.line_break)\n","        print('Creating data dictionaries.')\n","        self.label_dict = {} #label_dict will hold the class labels for the training data\n","        self.abstract_dict = {} #abstract_dict will hold the input abstracts\n","        self.corpus_list = [] #corpus_list will maintain a list of all words in the corpus for statistical purposes\n","        print('Dictionaries created.')\n","        \n","        \n","    def data_setup(self, input_df, data_type = 'train'):\n","        #Data setup takes a dataframe input contain one column of ids and one column of abstracts.\n","        #If the data type is train, then an additional column of labels will exist.\n","        \n","        #Extract the dataframe into lists for easier loading into dictionaries.\n","        print(self.line_break)\n","        print('Extracting ids and abstract from data frame.')\n","        try:\n","            abstract_id = input_df.train_id.to_list()\n","        except:\n","            abstract_id = input_df.test_id.to_list()\n","            \n","        abstract = input_df.abstract.to_list()\n","        print('Labels and Abstract loaded into lists')\n","        \n","        #If the data type is train, then also load the labels.\n","        if data_type == 'train':\n","            print(self.line_break)\n","            print('Extracting Labels from train data.')\n","            label = input_df.label.to_list()\n","            print('Labels extracted.')\n","        \n","        print(self.line_break)\n","        self.total_documents = len(abstract_id)\n","        print('The total number of documents in the corpus is ',self.total_documents,'.')\n","\n","        print(self.line_break)\n","        print('Loading the data into dictionaries')\n","        #Load the data into dictionaries for processing\n","        for n in range(0, len(abstract_id)):\n","            if data_type == 'train':\n","                self.label_dict[abstract_id[n]] = label[n]\n","\n","            self.abstract_dict[abstract_id[n]] = abstract[n]\n","        print('Data loaded.')\n","        \n","        self.data_type = data_type\n","        \n","    def clean_data(self):\n","            \n","        def get_wordnet_pos(word):\n","          #This function takes the input word and returns a pos_tag based on the wordnet package.\n","            tag = nltk.pos_tag([word])[0][1][0].upper()\n","            res_dict = {\"J\": wordnet.ADJ,\n","                        \"N\": wordnet.NOUN,\n","                        \"V\": wordnet.VERB,\n","                        \"R\": wordnet.ADV}\n","\n","            return res_dict.get(tag, wordnet.NOUN)\n","                \n","        \n","        def clean_line(input_string):\n","            #A funtion that will clean a single input string of text.\n","            \n","            #Remove everything that isn't a character or space, repalce with whitespace to split out equations.\n","            input_string = re.sub(r'[^\\w\\s]',' ', input_string)\n","\n","            #Convert all the characters to lower case.\n","            input_string = input_string.lower().split()\n","            \n","            #Strip punctuation.\n","            table = str.maketrans('', '', string.punctuation)#Create a mapping table that maps puncuation to an empty string.\n","            input_string = [word.translate(table) for word in input_string]#Apply the mapping to each word to remove punctuation.\n","            \n","            #Remove any digits\n","            input_string = [re.sub(\"[0-9]\", \"\", word) for word in input_string]\n","            \n","            #Remove stop words.\n","            input_string = [word for word in input_string if word not in stopwords]\n","            input_string = [word for word in input_string if word != '']# Remove any leftover blank entries.\n","            \n","            #Lemmatize all the words to get each words root lemma.\n","            lemmatizer = WordNetLemmatizer()\n","            input_string = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in input_string]\n","            \n","            #Remove words less that 3 characters.\n","            input_string = [word for word in input_string if len(word) > 2]\n","            \n","            #Return the cleaned string to the calling function.\n","            return input_string\n","        \n","        \n","        #Create a list to hold all words from the text.\n","        self.corpus_list = []\n","        \n","        print(self.line_break)\n","        print('Cleaning Abstract Data.')\n","        #Set up a progress bar as pbar equal to the length of the absract dict.\n","        with notebook.tqdm(total=len(self.abstract_dict)) as pbar:\n","\n","            #iterate through each abstract\n","            for key in self.abstract_dict:\n","                #Send each abstract to the cleaning function and use the returned clean text in its place.\n","                self.abstract_dict[key] = clean_line(self.abstract_dict[key])\n","                \n","                #Add the unique list of the words generated in the abstract to the corpus_list.\n","                self.corpus_list += list(set(self.abstract_dict[key]))\n","                \n","                #Update the progress bar by 1.\n","                pbar.update(1)\n","                \n","        print('Cleaning Complete.')\n","\n","    def get_result(self):\n","        #This function consolidates the cleaned data and returns it to the calling function as a list, where each element is a label, abstract pair for train data\n","        #And an absract only for test data.\n","        output_list = []\n","        \n","        for key in self.abstract_dict:\n","            \n","            if self.data_type == 'train':\n","                #Insert the label to the front of the list\n","                self.abstract_dict[key].insert(0, self.label_dict[key])\n","            \n","            #Insert the id to the front of the list\n","            self.abstract_dict[key].insert(0, str(key))\n","            self.abstract_dict[key].append('\\n')\n","            \n","            output_list.append(','.join(self.abstract_dict[key]))\n","\n","        return output_list"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBh4ffU3iirc","executionInfo":{"status":"ok","timestamp":1604632339472,"user_tz":-420,"elapsed":388394,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"d5402949-a753-4a31-b6b9-f22a277a56ce","colab":{"base_uri":"https://localhost:8080/","height":450,"referenced_widgets":["07069ce96d3f40339a6484b5fb733b77","304f08ff2e6741c39d424d3301918aee","f2bf93e070a5403d83d6623d73bcd499","86ed3f720f6f4585ade5315cc8a1d458","ec796c5b8acc45709e48d51168e859b0","32556fbc3d014efe8e823172504c99d4","6ad89958a8a446a982aed19cb13d35d9","44b58a73bdc441b6ae06f63187f28372"]}},"source":["#Instantiate the text_processor class.\n","train_corpus = text_processor()\n","#Load in the raw training data for the text processor using pandas.\n","train_df = pd.read_csv(home_directory+train_file)\n","#Pass the test data to the text_processor funciton, note that the function assumes data is training data by default.\n","train_corpus.data_setup(train_df)\n","#Clean the input data.\n","train_corpus.clean_data()\n","#Return the cleaned test data to a list.\n","cleaned_data_train = train_corpus.get_result()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\n","---------------\n","Creating data dictionaries.\n","Dictionaries created.\n","\n","---------------\n","Extracting ids and abstract from data frame.\n","Labels and Abstract loaded into lists\n","\n","---------------\n","Extracting Labels from train data.\n","Labels extracted.\n","\n","---------------\n","The total number of documents in the corpus is  29638 .\n","\n","---------------\n","Loading the data into dictionaries\n","Data loaded.\n","\n","---------------\n","Cleaning Abstract Data.\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07069ce96d3f40339a6484b5fb733b77","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=29638.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Cleaning Complete.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ahHlSgPYnm5h","executionInfo":{"status":"ok","timestamp":1604632437341,"user_tz":-420,"elapsed":486230,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"2ad3840e-9574-4ef2-909d-227f4eb617be","colab":{"base_uri":"https://localhost:8080/","height":383,"referenced_widgets":["8272a0204ebb4ca482d52ab2c9175cd5","6ac4ffeaf80947668ba489855852fa25","72d9bbf42a1347ecbeaaa387424d7d97","e58f96c4fd2f4e8a993f6b8dbf82761f","4b4a86904bd04257925f57677c06c872","23db9e67e4004e5193fd0236359f9094","0f3f432c5d43437d9f1f5424e9337627","f7902310a3b34ea99df4bb87e856a643"]}},"source":["#Instantiate the text_processor class.\n","test_corpus = text_processor()\n","#Load in the raw training data for the text processor using pandas.\n","test_df = pd.read_csv(home_directory + test_file)\n","#Pass the test data to the text_processor funciton, ensuring it is identified as test data.\n","test_corpus.data_setup(test_df, 'test')\n","#Clean the input data.\n","test_corpus.clean_data()\n","#Return the cleaned test data to a list.\n","cleaned_data_test = test_corpus.get_result()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n","---------------\n","Creating data dictionaries.\n","Dictionaries created.\n","\n","---------------\n","Extracting ids and abstract from data frame.\n","Labels and Abstract loaded into lists\n","\n","---------------\n","The total number of documents in the corpus is  7410 .\n","\n","---------------\n","Loading the data into dictionaries\n","Data loaded.\n","\n","---------------\n","Cleaning Abstract Data.\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8272a0204ebb4ca482d52ab2c9175cd5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=7410.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Cleaning Complete.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bqcnYht2kqv7","executionInfo":{"status":"ok","timestamp":1604632437346,"user_tz":-420,"elapsed":486227,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Process the cleaned data into the neccessary format for transition into the fastai package.\n","\n","clean_train = []\n","\n","#Split each clean record into individual tokens.\n","for line in cleaned_data_train:\n","    clean_train.append(line.strip().split(','))\n","\n","#Remove the train_id value (this will be the same as the index when we move into a dataframe.)\n","for n in range(0,len(clean_train)):\n","    clean_train[n] = clean_train[n][1:]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"8bgfKcbNk0iu","executionInfo":{"status":"ok","timestamp":1604632447345,"user_tz":-420,"elapsed":496219,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["train_df = pd.DataFrame(clean_train)# Load the abstract and label into a dataframe\n","#Create a new column which takes the abstract words only and omits the label into a new column.\n","train_df['Words'] = train_df[train_df.columns[1:]].apply(\n","    lambda x: ' '.join(x.dropna().astype(str)),\n","    axis=1)\n","#Remove the previously loaded words which were represented as columns.\n","train_df.drop(train_df.iloc[:,1:281], inplace=True, axis=1)\n","\n","#Rename the labels column to an appropriate title.\n","train_df=train_df.rename(columns = {0:'Label'})"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCw9VqiXk3Ni","executionInfo":{"status":"ok","timestamp":1604608692877,"user_tz":-420,"elapsed":461167,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"45f79da1-ddee-4f45-d761-f2b22379af1e","colab":{"base_uri":"https://localhost:8080/","height":447}},"source":["#Return the first 5 rows of the training data for visual inspection.\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cs</td>\n","      <td>save special case current training method generative adversarial network gans best guaranteed converge local nash equilibrium lne lnes however arbitrarily far actual nash equilibrium implies guarantee quality found generator classifier paper proposes model gans explicitly finite game mixed strategy thereby ensure every lne formulation propose solution method proven monotonically converge resource bound nash equilibrium increase computational resource find well solution empirically demonstrate method less prone typical gan problem mode collapse produce solution less exploitable produce gans...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>math.DS</td>\n","      <td>consider dynamical system finitely many equilibrium perturbed small noise addition control expensive control control process optimal ergodic criterion run cost consists sum control effort penalty function state space study optimal stationary distribution control process variance noise becomes vanishingly small show depend relative magnitude noise variance run cost control one identify three regime optimal control force invariant distribution process concentrate near equilibrium characterize accord regime also obtain moment bound optimal stationary distribution moreover show vicinity point ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cs</td>\n","      <td>consider discrete dynamical system ant like agent engage sequence pursuit graph environment agent emerge one one equal time interval source vertex pursue greedily attempt close distance immediate predecessor agent emerge arrive destination point pursuit investigate continuous set discrete time underlie environment regular grid setting agent walk provably converge shortest path furthermore assume certain natural probability distribution move choice agent grid case multiple shortest path agent predecessor walk converge uniform distribution shortest path study evolution agent walk general fin...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cs</td>\n","      <td>retrofit technique inject external resource word representation compensate weakness distribute representation semantic relational knowledge word implicitly retrofit word vector expansional technique outperforms retrofit word similarity task word vector generalization paper propose unsupervised extrofitting expansional retrofit extrofitting without external semantic lexicon also propose deep extrofitting depth stack extrofitting combination extrofitting retrofit experiment glove show method outperform previous method word similarity task require synonym external resource lastly show effect ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cs</td>\n","      <td>approach decision make uncertainty belief function framework review method show blend criterion decision ignorance maximum expect utility principle bayesian decision theory distinction make method construct complete preference relation among act allow incomparability act due lack information method developed imprecise probability framework applicable dempster shafer context also review shafer constructive decision theory substitute notion goal utility described contrast approach paper end point need carry deeper investigation fundamental issue related decision make belief function ass desc...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Words\n","0       cs  save special case current training method generative adversarial network gans best guaranteed converge local nash equilibrium lne lnes however arbitrarily far actual nash equilibrium implies guarantee quality found generator classifier paper proposes model gans explicitly finite game mixed strategy thereby ensure every lne formulation propose solution method proven monotonically converge resource bound nash equilibrium increase computational resource find well solution empirically demonstrate method less prone typical gan problem mode collapse produce solution less exploitable produce gans...\n","1  math.DS  consider dynamical system finitely many equilibrium perturbed small noise addition control expensive control control process optimal ergodic criterion run cost consists sum control effort penalty function state space study optimal stationary distribution control process variance noise becomes vanishingly small show depend relative magnitude noise variance run cost control one identify three regime optimal control force invariant distribution process concentrate near equilibrium characterize accord regime also obtain moment bound optimal stationary distribution moreover show vicinity point ...\n","2       cs  consider discrete dynamical system ant like agent engage sequence pursuit graph environment agent emerge one one equal time interval source vertex pursue greedily attempt close distance immediate predecessor agent emerge arrive destination point pursuit investigate continuous set discrete time underlie environment regular grid setting agent walk provably converge shortest path furthermore assume certain natural probability distribution move choice agent grid case multiple shortest path agent predecessor walk converge uniform distribution shortest path study evolution agent walk general fin...\n","3       cs  retrofit technique inject external resource word representation compensate weakness distribute representation semantic relational knowledge word implicitly retrofit word vector expansional technique outperforms retrofit word similarity task word vector generalization paper propose unsupervised extrofitting expansional retrofit extrofitting without external semantic lexicon also propose deep extrofitting depth stack extrofitting combination extrofitting retrofit experiment glove show method outperform previous method word similarity task require synonym external resource lastly show effect ...\n","4       cs  approach decision make uncertainty belief function framework review method show blend criterion decision ignorance maximum expect utility principle bayesian decision theory distinction make method construct complete preference relation among act allow incomparability act due lack information method developed imprecise probability framework applicable dempster shafer context also review shafer constructive decision theory substitute notion goal utility described contrast approach paper end point need carry deeper investigation fundamental issue related decision make belief function ass desc..."]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"68PkAnCqldkS","executionInfo":{"status":"ok","timestamp":1604632447355,"user_tz":-420,"elapsed":496221,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#remove the \"there is none\" row\n","train_df = train_df.drop(train_df.index[26822])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwk9vNvTk57R","executionInfo":{"status":"ok","timestamp":1604632447356,"user_tz":-420,"elapsed":496215,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Create a mask for identifying samples for our validation set by randomly selecting rows withing the dataframe.\n","#The mask will create an approximate 80-20 split for training vs validation data.\n","msk = np.random.rand(len(train_df)) > 0.8"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsw_g-Cvk8Iz","executionInfo":{"status":"ok","timestamp":1604632447357,"user_tz":-420,"elapsed":496208,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Create a new column that identifies the rows that will be held back for validation.\n","train_df['test'] = msk"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfZ8rTUYk_QG","executionInfo":{"status":"ok","timestamp":1604608692880,"user_tz":-420,"elapsed":461151,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"c09edf34-c53c-4758-a923-69c2db083135","colab":{"base_uri":"https://localhost:8080/","height":447}},"source":["#Return the first 5 rows of the training data for visual inspection.\n","train_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>Words</th>\n","      <th>test</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cs</td>\n","      <td>save special case current training method generative adversarial network gans best guaranteed converge local nash equilibrium lne lnes however arbitrarily far actual nash equilibrium implies guarantee quality found generator classifier paper proposes model gans explicitly finite game mixed strategy thereby ensure every lne formulation propose solution method proven monotonically converge resource bound nash equilibrium increase computational resource find well solution empirically demonstrate method less prone typical gan problem mode collapse produce solution less exploitable produce gans...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>math.DS</td>\n","      <td>consider dynamical system finitely many equilibrium perturbed small noise addition control expensive control control process optimal ergodic criterion run cost consists sum control effort penalty function state space study optimal stationary distribution control process variance noise becomes vanishingly small show depend relative magnitude noise variance run cost control one identify three regime optimal control force invariant distribution process concentrate near equilibrium characterize accord regime also obtain moment bound optimal stationary distribution moreover show vicinity point ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cs</td>\n","      <td>consider discrete dynamical system ant like agent engage sequence pursuit graph environment agent emerge one one equal time interval source vertex pursue greedily attempt close distance immediate predecessor agent emerge arrive destination point pursuit investigate continuous set discrete time underlie environment regular grid setting agent walk provably converge shortest path furthermore assume certain natural probability distribution move choice agent grid case multiple shortest path agent predecessor walk converge uniform distribution shortest path study evolution agent walk general fin...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cs</td>\n","      <td>retrofit technique inject external resource word representation compensate weakness distribute representation semantic relational knowledge word implicitly retrofit word vector expansional technique outperforms retrofit word similarity task word vector generalization paper propose unsupervised extrofitting expansional retrofit extrofitting without external semantic lexicon also propose deep extrofitting depth stack extrofitting combination extrofitting retrofit experiment glove show method outperform previous method word similarity task require synonym external resource lastly show effect ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cs</td>\n","      <td>approach decision make uncertainty belief function framework review method show blend criterion decision ignorance maximum expect utility principle bayesian decision theory distinction make method construct complete preference relation among act allow incomparability act due lack information method developed imprecise probability framework applicable dempster shafer context also review shafer constructive decision theory substitute notion goal utility described contrast approach paper end point need carry deeper investigation fundamental issue related decision make belief function ass desc...</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Label  ...   test\n","0       cs  ...  False\n","1  math.DS  ...  False\n","2       cs  ...  False\n","3       cs  ...  False\n","4       cs  ...  False\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"TLnV0D5klk9m"},"source":["#The training data has now been processed, save a copy to the data folder for record keeping purposes.\n","train_df.to_csv(home_directory+data_directory+'/clean_train_dataset.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlJfg1kzmeM1","executionInfo":{"status":"ok","timestamp":1604632447358,"user_tz":-420,"elapsed":496202,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Process the cleaned test data into the neccessary format for transition into the fastai package.\n","\n","clean_test = []\n","\n","#Split each clean record into individual tokens.\n","for line in cleaned_data_test:\n","    clean_test.append(line.strip().split(','))\n","\n","#Remove the test_id value (this will be the same as the index when we move into a dataframe.)\n","for n in range(0,len(clean_test)):\n","    clean_test[n] = clean_test[n][1:]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZIzPtQDpMc3","executionInfo":{"status":"ok","timestamp":1604632449682,"user_tz":-420,"elapsed":498519,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["# testing data\n","test_df = pd.DataFrame(clean_test)# Load the abstract and label into a dataframe\n","#Create a new column which takes the abstract words and joins them into a single column.\n","test_df['text'] = test_df[test_df.columns[0:]].apply(\n","    lambda x: ' '.join(x.dropna().astype(str)),\n","    axis=1)\n","#Remove the previously loaded words which were represented as columns.\n","test_df.drop(test_df.iloc[:,0:280], inplace=True, axis=1)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"qDwbj3uqpTBA","executionInfo":{"status":"ok","timestamp":1604608696035,"user_tz":-420,"elapsed":419161,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"e9e2a2af-4d19-4454-c372-6c951517fcdc","colab":{"base_uri":"https://localhost:8080/","height":839}},"source":["#Return the first five records for visual inspection.\n","test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>method model average become important tool deal model uncertainty example situation large amount different theory exist common economics model average natural formal response model uncertainty bayesian framework paper deal bayesian model average important role prior assumption bayesian procedure highlight addition frequentist model average method also discuss numerical method implement method explain point reader freely available computational resource main focus uncertainty regard choice covariates normal linear regression model paper also cover challenge setting particular emphasis sampl...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>unmanned aerial vehicle uav system increasingly use broad range scenario application however deployment urban area pose important technical challenge one prominent concern robustness communication ground station uavs highly dynamic crowd spectrum indeed compete data stream may create local temporary congestion impair ground station control uavs main contribution paper robust multi path communication framework uav system framework continuously probe performance multiple wireless multi hop path ground station uav dynamically selects path provide best performance support timely control numeri...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>paper propose new loss function call generalize end end gee loss make training speaker verification model efficient previous tuple base end end tee loss function unlike tee gee loss function update network way emphasizes example difficult verify step training process additionally gee loss require initial stage example selection property model new loss function decrease speaker verification eer reduce training time time also introduce multireader technique allows domain adaptation training accurate model support multiple keywords google hey google well multiple dialect</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>show integrate weak morphism lie algebra cross module weak morphism lie group develop theory butterfly term linfty algebra particular obtain new description bicategory term linfty algebra use butterfly give functorial construction connect cover lie group also discus notion homotopy fiber morphism term linfty algebra</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>caustic occur widely dynamic take shape classify catastrophe theory finite wavelength produce interference pattern contain network vortex phase singularity investigate caustic quantize field focus collective dynamic quantum spin show follow quench caustic generate fock space amplitude specify many body configuration accessible experiment cold atom ion photon granularity quantum field remove singularity include phase singularity convert point vortex nonlocal vortex annihilate pair quantization scale increase furthermore continuous scale law wave catastrophe replace discrete version quantum ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7405</th>\n","      <td>statistical inference evolutionary parameter molecular sequence data relies coalescent model account share genealogical ancestry sample however inferential algorithm scale available data set strategy improve computational efficiency rely simpler coalescent mutation model result small hidden state space estimate cardinality state space genealogical tree different resolution essential decide best model strategy give dataset knowledge neither exact approximate method determine cardinality propose sequential importance sample algorithm estimate cardinality space genealogical tree different coa...</td>\n","    </tr>\n","    <tr>\n","      <th>7406</th>\n","      <td>present deep learn framework base generative adversarial network gan perform super resolution coherent image system demonstrate framework enhance resolution pixel size limited diffraction limited coherent image system experimentally validate capability deep learn base coherent image approach super resolve complex image acquire use lensfree chip holographic microscope resolution pixel size limited use gan base approach also improve resolution lens base holographic image system limited resolution numerical aperture objective lens deep learn base super resolution framework broadly apply enhan...</td>\n","    </tr>\n","    <tr>\n","      <th>7407</th>\n","      <td>cell receptor tcr repertoire data contain information infection could use disease diagnostics vaccine development extract information remains major challenge developed statistical framework detect tcr clone proliferation contraction longitudinal repertoire data apply framework data three pair identical twin immunize yellow fever vaccine identify respond tcrs donor validate use three independent assay respond tcrs mostly private albeit high overlap twin could well predict use classifier base sequence similarity method also apply sample obtain post infection make suitable systematic discover...</td>\n","    </tr>\n","    <tr>\n","      <th>7408</th>\n","      <td>paper provide modern synthesis classic inverse compositional algorithm dense image alignment first discus assumption make well establish technique subsequently propose relax assumption incorporate data driven prior model specifically unroll robust version inverse compositional algorithm replace multiple component algorithm use expressive model whose parameter train end end fashion data experiment several challenge rigid motion estimation task demonstrate advantage combine optimization learn base technique outperform classic inverse compositional algorithm well data driven image pose regres...</td>\n","    </tr>\n","    <tr>\n","      <th>7409</th>\n","      <td>experiment currently harvest lhc collision data cern performance electromagnetic calorimeter ecal constantly monitor work start ass need change detector ensure adequate performance high luminosity lhc lhc run plan beyond paper result run beam test laboratory measurement combine anticipate detector performance evolution lhc various study illustrate provide useful choice electromagnetic calorimetry lhc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7410 rows × 1 columns</p>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text\n","0     method model average become important tool deal model uncertainty example situation large amount different theory exist common economics model average natural formal response model uncertainty bayesian framework paper deal bayesian model average important role prior assumption bayesian procedure highlight addition frequentist model average method also discuss numerical method implement method explain point reader freely available computational resource main focus uncertainty regard choice covariates normal linear regression model paper also cover challenge setting particular emphasis sampl...\n","1     unmanned aerial vehicle uav system increasingly use broad range scenario application however deployment urban area pose important technical challenge one prominent concern robustness communication ground station uavs highly dynamic crowd spectrum indeed compete data stream may create local temporary congestion impair ground station control uavs main contribution paper robust multi path communication framework uav system framework continuously probe performance multiple wireless multi hop path ground station uav dynamically selects path provide best performance support timely control numeri...\n","2                             paper propose new loss function call generalize end end gee loss make training speaker verification model efficient previous tuple base end end tee loss function unlike tee gee loss function update network way emphasizes example difficult verify step training process additionally gee loss require initial stage example selection property model new loss function decrease speaker verification eer reduce training time time also introduce multireader technique allows domain adaptation training accurate model support multiple keywords google hey google well multiple dialect \n","3                                                                                                                                                                                                                                                                                              show integrate weak morphism lie algebra cross module weak morphism lie group develop theory butterfly term linfty algebra particular obtain new description bicategory term linfty algebra use butterfly give functorial construction connect cover lie group also discus notion homotopy fiber morphism term linfty algebra \n","4     caustic occur widely dynamic take shape classify catastrophe theory finite wavelength produce interference pattern contain network vortex phase singularity investigate caustic quantize field focus collective dynamic quantum spin show follow quench caustic generate fock space amplitude specify many body configuration accessible experiment cold atom ion photon granularity quantum field remove singularity include phase singularity convert point vortex nonlocal vortex annihilate pair quantization scale increase furthermore continuous scale law wave catastrophe replace discrete version quantum ...\n","...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...\n","7405  statistical inference evolutionary parameter molecular sequence data relies coalescent model account share genealogical ancestry sample however inferential algorithm scale available data set strategy improve computational efficiency rely simpler coalescent mutation model result small hidden state space estimate cardinality state space genealogical tree different resolution essential decide best model strategy give dataset knowledge neither exact approximate method determine cardinality propose sequential importance sample algorithm estimate cardinality space genealogical tree different coa...\n","7406  present deep learn framework base generative adversarial network gan perform super resolution coherent image system demonstrate framework enhance resolution pixel size limited diffraction limited coherent image system experimentally validate capability deep learn base coherent image approach super resolve complex image acquire use lensfree chip holographic microscope resolution pixel size limited use gan base approach also improve resolution lens base holographic image system limited resolution numerical aperture objective lens deep learn base super resolution framework broadly apply enhan...\n","7407  cell receptor tcr repertoire data contain information infection could use disease diagnostics vaccine development extract information remains major challenge developed statistical framework detect tcr clone proliferation contraction longitudinal repertoire data apply framework data three pair identical twin immunize yellow fever vaccine identify respond tcrs donor validate use three independent assay respond tcrs mostly private albeit high overlap twin could well predict use classifier base sequence similarity method also apply sample obtain post infection make suitable systematic discover...\n","7408  paper provide modern synthesis classic inverse compositional algorithm dense image alignment first discus assumption make well establish technique subsequently propose relax assumption incorporate data driven prior model specifically unroll robust version inverse compositional algorithm replace multiple component algorithm use expressive model whose parameter train end end fashion data experiment several challenge rigid motion estimation task demonstrate advantage combine optimization learn base technique outperform classic inverse compositional algorithm well data driven image pose regres...\n","7409                                                                                                                                                                                                     experiment currently harvest lhc collision data cern performance electromagnetic calorimeter ecal constantly monitor work start ass need change detector ensure adequate performance high luminosity lhc lhc run plan beyond paper result run beam test laboratory measurement combine anticipate detector performance evolution lhc various study illustrate provide useful choice electromagnetic calorimetry lhc \n","\n","[7410 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"xWK3uBtJpa89"},"source":["#The test data has now been processed, save a copy to the data folder for record keeping purposes.\n","test_df.to_csv(home_directory+data_directory+'/test-dataset.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECgwVBaNmdsK"},"source":["**Section 5**\n","\n","Commence Feature Engineering using the fastai package to construct an autoencoder."]},{"cell_type":"code","metadata":{"id":"GCSFqgLIpxbb","executionInfo":{"status":"ok","timestamp":1604632449687,"user_tz":-420,"elapsed":498517,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Load in the full train dataset to prepare for the encoder training.\n","df = train_df.copy()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjI07sLiSorE","executionInfo":{"status":"ok","timestamp":1604632449689,"user_tz":-420,"elapsed":498486,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"262419cb-2f4e-4a98-ec22-dfd9ad0abfbf","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Reset the seed value according to the earlier defined function.\n","reset_seed()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Seed reset to value  333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GTvWklTQp1On","executionInfo":{"status":"ok","timestamp":1604632501855,"user_tz":-420,"elapsed":550603,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"c8ad8777-2f94-4e13-b686-93257b1e2b70","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["def initialise_language_model():\n","  #Construct a data loader for the language model.\n","  dl_lm = TextDataLoaders.from_df(df, text_col='Words', is_lm=True, valid_pct=0.1)\n","\n","  #Declare a learning model, based on a Long-Short Term Memory to predict the next word in the text data.\n","  model = language_model_learner(dl_lm, AWD_LSTM, metrics = accuracy, wd=0.1)\n","\n","  return model\n","\n","#Initialise a new language model using the fastai package.\n","learn = initialise_language_model()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Va4wVyAfyL6t","executionInfo":{"status":"ok","timestamp":1604632533501,"user_tz":-420,"elapsed":582215,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"3e50c89d-a45f-4a36-9f13-b7d856fef7a5","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["#Use the lr_find method to select the best learning rate for the one-cycle_fit method.\n","best_lr = learn.lr_find()"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV1b3/8fc38xxISJjCjMyDQAQUUayttVyrVltrxbEWtbWDrW2tt/de622vrbW1rXWucytap5+lA2oHcaxIQJAZmQfJABnJPKzfH+cAMQZIIDt7n5zP63nOAzlnn70/OWK+WWvttZY55xARkegV43cAERHxlwqBiEiUUyEQEYlyKgQiIlFOhUBEJMqpEIiIRLk4vwN0Vp8+fdzQoUP9jiEiElGWLVu21zmX095rEVcIhg4dSkFBgd8xREQiipltP9xr6hoSEYlyKgQiIlFOhUBEJMqpEIiIRDkVAhGRKKdCICIS5VQIREQiwN/XFrGpuMqTc6sQiIgEnHOOrz25jOeX7/bk/CoEIiIBV9fYQmOzIyMp3pPzqxCIiARcZV0jABnJ3iwGoUIgIhJwFbWhQpCZrBaBiEhUqgwXgojsGjKzb5nZajNbY2Y3HOaYOWa2InzMa17mERGJRIe6hrwpBJ6tPmpmE4D5wHSgAXjJzP7inNvU6phewL3A2c65HWaW61UeEZFIFcldQ2OBJc65GudcE/AacEGbYy4BXnDO7QBwzhV7mEdEJCJV1jYBkJEUeYPFq4HZZpZtZinAXGBQm2NGAb3NbLGZLTOzy9s7kZldY2YFZlZQUlLiYWQRkeA5OEYQaV1Dzrl1ZnY78ApQDawAmtu5/jTgTCAZ+LeZveOc29jmXA8CDwLk5+c7rzKLiARRRW0jKQmxxMd687u7p4PFzrmHnXPTnHOnAWXAxjaH7AJeds5VO+f2Aq8Dk73MJCISaSrrGj27Ywi8v2soN/znYELjAwvaHPIn4FQziwt3H80A1nmZSUQk0lTWNnk2mQy837P4eTPLBhqB651z5WZ2HYBz7v5w99FLwPtAC/CQc261x5lERCJKRW2jZ3cMgceFwDk3u53n7m/z9R3AHV7mEBGJZJV1jfTLSPLs/JpZLCIScJV1jZ7dMQQqBCIigVdR423XkAqBiEiAtbQ4quqbPJtMBioEIiKBtr+hCee8m0wGKgQiIoFWUePtrGJQIRARCbSDK49G6oQyERE5PgcXnPNwQpkKgYhIgHm9BDWoEIiIBJq6hkREopzXS1CDCoGISKBV1jZiBumJGiMQEYlKlXVNpCfGERNjnl1DhUBEJMAqa71dZwhUCEREAs3rJahBhUBEJNC83p0MVAhERALN693JQIVARCTQ1DUkIhLl1DUkIhLFGptbqGlo1l1DIiLRqrIb1hkCFQIRkcCqrPN+5VFQIRARCayD6wxpjEBEJDp1xxLUoEIgIhJYB5egViEQEYlOB3cnU9eQiEh0UteQiEiUq6xrJD7WSIr39ke1CoGISEBV1oZmFZt5txcBqBCIiARWd6wzBCoEIiKBVVnXRLoKgYhI9Ap1DXk7qxg8LgRm9i0zW21ma8zshiMcd5KZNZnZ573MIyISSSojvWvIzCYA84HpwGTgHDMb2c5xscDtwCteZRERiUSVdd7vVwzetgjGAkucczXOuSbgNeCCdo77BvA8UOxhFhGRiOKcC+1O5vFkMvC2EKwGZptZtpmlAHOBQa0PMLOBwOeA+450IjO7xswKzKygpKTEs8AiIkFR19hCQ3NLZHcNOefWcajL5yVgBdDc5rBfAzc551qOcq4HnXP5zrn8nJwcT/KKiATJoXWGvB8s9vQKzrmHgYcBzOw2YFebQ/KBp8OTJfoAc82syTn3ope5RESCrruWoAaPC4GZ5Trnis1sMKHxgZmtX3fODWt17GPAX1QERESgvJvWGQKPCwHwvJllA43A9c65cjO7DsA5d7/H1xYRiVil1Q0AZKUmeH4tr7uGZrfzXLsFwDl3pZdZREQiSXlNqBD07oZCEDUzixubW9hZWkNj8xHHpUVEAqG0OtQ11Dslgu8aCpq/vP8hs3/+Ktv3VfsdRUTkqMprGkiMiyE5Ptbza0VNIRjYKwWAXWW1PicRETm60uoGslITPF+CGqKpEPROBmB3uQqBiARfWU0DvVK8Hx+AKCoEfdMTiY0xdqtFICIRoKymkaxU78cHIIoKQVxsDP0yktQiEJGIUFatFoEnBvZOVotARCJCaU0DWSoEXS+vV7JaBCISeM0tjoraxm6ZQwBRVggG9k6mqLJOcwlEJNAqahtxrnvmEEC0FYJeybQ4KKyo8zuKiMhhdefyEhBthUC3kIpIBDi4vITGCLrewF7hQqABYxEJsAMtAhUCDwzopRaBiARfeU14nSHNI+h6SfGx9ElLVItARAKtVF1D3hrYW7eQikiwlVU3kBAXQ0qC9wvOQRQWAs0lEJGgKwtPJuuOBecgCgvBgRZBS4vzO4qISLtKqxvp1U1zCCAaC0GvZBqaWthbXe93FBGRdpXVNHTbHAKI0kIAuoVURIKrrKah25aXgGgsBJpUJiIBV1bd0G3LS0A0FwK1CEQkgJpbHOW1jd228ihEYSHISIonPSlOLQIRCaTK8IJz3bUXAURhIYDQOIFaBCISRAcmk2mw2GN5mlQmIgF1cME5FQJvqUUgIkFVWh1eZ0iDxd4a2DuZqvomKmob/Y4iIvIRZd288ihEayHolQJ8/M6h5hbH955dyUUP/Fszj0XEF2UaI+geB24h3VlWc/A55xz//afVPLtsF+9uLeWf64v9iiciUay0poGE2O5bcA6itBAM65NKWmIc33t2JY++tZXG5hbu/PtGFizZwbWnDWdgr2QefH2z3zFFJAqVVTfQOzW+2xacgygtBJnJ8bx4/SlMHtSLW/+8ltN//iq//dcmvjR9ED/4zBi+MnsYS7eVsWx7md9RRSTKlNU0duv4AERpIQAYmZvOE1+ezoOXTSMpIZbzThzAT86fiJlxUf4gMpPj1SoQkW4XWl6iBxUCM/uWma02szVmdkM7r88zs/fNbJWZvW1mk73M0871OWt8P/514xx+c/EUYmNCTbHUxDgumzmEV9YWsaVkf3dGEpEoV9rNK4+Ch4XAzCYA84HpwGTgHDMb2eawrcDpzrmJwI+BB73K01lXnDKU+NgYfvfGVr+jeK68poFX1hTy3o4y6hqb/Y4jEtXKa7p3LwKAOA/PPRZY4pyrATCz14ALgJ8fOMA593ar498B8jzM0yk56YlcODWP55fv4opThjCmX4bfkY7JztIaYmLs4PLbB+wqq+HlNUX8fW0hS7eV0Ry+XTY2xjghN43BWSlkpSaQlZpAbnoig7NTGJyVQl7vFJLiu+9uBpFo0tLiKPehReBlIVgN/J+ZZQO1wFyg4AjHXw0sau8FM7sGuAZg8ODBXRzz8L515gm8ur6Yyx9+l+e/egqDslK67drHyjnHrrJaXlpdyMKVH7JqdwUAJ+SmMWd0Dr1SEnh5TSHv7wo9P7pvOtedPpzTR+VSVtPA6t0VrN5dwfZ9Nby3s5yy6gaaWs2piDEYmp3KqL7pjMhNBaC6vpnq+iYS42PISkmgd2oCQ/ukcvLwbBUNkU6orGukxXXvZDIAc867iVNmdjXwNaAaWAPUO+faGys4A7gXONU5t+9I58zPz3cFBUeqJ11rQ2EVX7j/bfqkJfLsdSeTnZbYbdd2zrGhqIo9FXXUNjRT29BMWU0DxVX1FFXWUVnbSFxsDPGxRksL7CitYdu+amoaQt07Ewdmcu7kAZjB4g0lvLu1lIbmFibnZfKZif05e3w/hvZJPWqGvfsb2FFaw87SGrbsreaDoio2FFaxbV81ZkZqQiwpCXHUNzVTHl45ESApPoZTR+Ywc3gWyQmxxJgRG2NkpybQNyOJ3PREctITu/U2OZEg21Kyn0/88jV+9cXJfG5K13aQmNky51x+e6952SLAOfcw8HA4xG3ArnbCTQIeAj5ztCLgh9H90nnkypOY99ASrnpsKU98ebrny8PWNjSzcOVufv/OdlbvrvzY6wlxMfTLSCIjOY6mZkdTi8M5x6CsFGYMz2J4n1ROPSGHYa1+yH9l9nCq65uobmgiNz2pw1nMjJzwD+xpQ3p/5LXmFkeM8ZEf5M0tjoraRlbtruCf64r457pi/rGu6LDnH94nlQun5XHB1IH0z0w+7HEi0eDArOJAtgjMLBWodc61mNkoYAywyDl3xMV6zCzXOVdsZoOBV4CZzrnyVq8PBv4FXN5mvOCwurtFcMA/1xVx7e+XkZkcz3/OHcsFUwd68pvsi+/t5paFa6iobWRU3zQunTmE8QMySUmIJSUhlszkeDKTu3eyyfFwzrGvuoGWFkeLg8bmFvbur6e4qp4Py2tZtLqQd7eWEmNw8ohs5k7sz6fH96NPF7S8Gppa2FhUxdo9lWzbW832cKvGgJz0JHIzEslJSyQrNdSd1TslnvSkeNISY0lNjCMxLpb4WCM+NobEuJiI+cwlcv1jbRFfeaKAP10/i8mDenXpuY/UIuhoIVgGzAZ6A28BS4EG59y8o7zvDSAbaAS+45z7p5ldB+Ccu9/MHgIuBLaH39J0uKAH+FUIANZ8WMF/v7ia5TvKmT4siy/mD6JPeiJ90hIYmp1KauKxN7BqGpq45U9reHbZLvKH9Ob7Z4/hpKG9o+KHz/Z91Ty3bBd/Xvkh2/bVEGMwbUhv8odmMW1wbyblZZIcnm4fY0ZKQuxHPpfS6gaWbitl3Z5KiirrKamqY3d5HZuKq2hsPjQIntc7mcFZKZgZxZV1FFfVUxpe4KsjkuNjSU6IpV9GEqeMyObUE/owfVgWKQmeNqwlijxTsJPvP/c+b3z/jC4fk+yKQrDcOTfVzL4BJDvnfm5mK5xzJ3Zp0g7wsxBAaFT/2WU7+emi9ZTXHGoQZSTFceNZo5k3YzBxsUe+K9c5x1ub9rFyV3m4a6eFRasL2Vyyn6+fMZJvnXnCUc/REznnWF9YxaJVe1i8sYS1H1Z+ZKD6gIS4GPpnJtE/M4nS6gY2Fh2a65GdmkBOeiL9MpMY0y+D8QMyGDcggyFZKe1+pk3NLZTXNlJW3UBZTSPV9U1U1Texv66JhqZmGpsdDc0t1De1UNvQRG1jM5uLq1m2vYyG5hbMoG96Enm9kxmUlcLY/ulMyuvFhIGZpB3HLwYSne5/bTM/W7Se1bd+usv//XTFGIGZ2cnAPEJ39wBE5e0gMTHGF08azHknDqSwoo591fUUV9bzhyXbuWXhGp56dwc//I+xnDKiz8EJaq29s2Ufv3xlA0u3HVq+Isagf2Yyf7h6BrNG9unObydQzIyx/TMY2z+D75w1mtqGZlbtrmDthxXhcRBoCXc1fVhey56KOvpnJnPeiQOZMSyLCQMzO32XUlxsDH3SEjvdFVXb0EzB9lKWbS9jV1ktu8pqeGfLPv7fe7vD3wsMy05l7IAMxvUPFaMx/dLpl5EUFa08OTbFlfWkJMR2+y8RHW0RnA7cCLzlnLvdzIYDNzjnvul1wLb8bhEcjnOOl9cU8uO/rGN3eS0ZSXHMHJ7NSUOzqKpvYldZDZuK9/P+rgr6ZiTy9U+cwIVTB5IUF0tMOwVDItPe/fWs2l3B+zsrWLungrV7KtlZemi588zkeCYOzOTT4/ty9oT+5KR3311oEnxfX7CcNR9W8up353T5uY+7a6jNyWKANOfcx29n6QZBLQQH1DU288raIt7etJc3N+1lV1ktZtA/I4m8rBTOGteXS2cO0f31UaSitpENhVWsL6xk3Z4q3t26j80l1cQYzBiWzafH9+WT4/qS1zv481TEWxfd/28weObak7v83F0xRrAAuA5oJjRQnAH8xjl3R1cG7YigF4K29u2vJz0pnoS46Ovzl/Y559hYtJ+/rtrD31btYVNxaIxjbP8Mzj9xAF/IH9TtM0slGObc8SoTBmZy9yVTu/zcXTFGMM45V2lm8wjN/v0BsAzo9kIQabpzAppEBjNjdL90RvdL5zufGsXWvdX8fW0hL60u5KeL1vPLVzYyd2I/rjhlKFMG9z76CaVHcM5RVFnPmWM7Ps+nq3S0EMSbWTxwPnC3c67RzLSXo0gXGNYnlWtOG8E1p41gQ2EVC5Zs54Xlu3lxxYfMGpnN9WeM5OTh2Rpk7uH214fuSsv1Ydyoo/0VDwDbgFTgdTMbAvgyRiDSk43ul86t503gnf88kx/OHcvGov1c8rslXHjf27y6vhgvl4QRfxVV1gPQN6P7WwQdKgTOubuccwOdc3NdyHbgDI+ziUSt1MQ45p82nDe+fwY/Pm88RZX1XPXYUs757ZssWrWHlnbmV0hkK66qAwhui8DMMs3sTjMrCD9+Sah1ICIeSoqP5bKTh/Lqd+fw889Porq+ia8+uZzP3v0mizeohdCTlFSFWgS5QW0RAI8AVcBF4Ucl8KhXoUTkoxLiYrgofxD/vHEOd140mYraRq58dCkXP/gO6/aol7YnKKoMtwgyAtoiAEY4525xzm0JP24FhnsZTEQ+LjbGuGBqHv+6cQ63njueTcX7Oe+et3j87W1qHUS44sp6kuNjSfdhaZKOFoJaMzv1wBdmNovQZjMi4oOEuBiuOGUor3z7NGaNyOaWhWuY/0RBpxbRk2ApqqonN8Of/Tk6WgiuA+4xs21mtg24G7jWs1Qi0iHZaYk8cuVJ/M8543h9414+/evX+df6w+//IMFVXFlH307sFdKVOnrX0Ern3GRgEjDJOTcF+ISnyUSkQ8yML586jBevn0V2agJffqyAm194n/31TX5Hk04orqonx4fxAeh4iwAA51xlqzWGvuNBHhE5RuMGZPCnr8/i2tOH8/TSnZxz1xvsLK3xO5Z0UOBbBIehaY4iAZMYF8vNnxnL0/NnUlrdwBcf+Ddb91b7HUuOYn99E9UNzb7cMQTHVwh0i4JIQM0Yns1T18ykrqmFix74NxuLqvyOJEdQXOnfZDI4SiEwsyozq2znUQUM6KaMInIMxg/I5JlrZ2LAxQ++c3CVUwme4ir/lpeAoxQC51y6cy6jnUe6c0778IkE3MjcdJ659mQM+MrjSymv0e2lQVQU5BaBiES+oX1SeeCyaXxYXsf1C5bT2NzidyRpw8/lJUCFQCQq5A/N4rYLJvLWpn3875/X+h1H2iiqrCMxLoaMJH86WtS9IxIlPj8tjw+Kqnjg9S1kJMdx46dGa7/sgCiuqqdvRpJve06oEIhEke+fPYaymgbueXUz6/ZU8asvnkhmcrzfsaJecWW9b+MDoK4hkagSG2PcfuEkfnzeeF7fWML597ylu4kCoKiqzrc7hkCFQCTqmBmXnTyUBfNnUlXXyOUPL6FMi9X5qqSynhy1CESku00flsUjV57E3v0NfPuZFdr1zCc1DU1U1TepRSAi/piU14v//uw4Fm8o4d7Fm/yOE5WKw3sVa4xARHxz6YzBnHfiAO78+0be3rzX7zhRx8+dyQ5QIRCJcmbGbZ+byPCcNL751HsUVtT5HSmq+L28BKgQiAiQmhjH/ZdOpaahmesXLKehSbOPu8uBQqCuIRHx3cjcdH7++Uks217GTxet8ztO1CiurCMhLsbX+RyeFgIz+5aZrTazNWZ2Qzuvm5ndZWabzOx9M5vqZR4RObJzJg3gy7OG8ehb21i48kO/40SF4qrQZDK/ZhWDh4XAzCYA84HpwGTgHDMb2eawzwAnhB/XAPd5lUdEOubmuWPIH9KbHzz/Ph9oHwPP7S6vZUBmsq8ZvGwRjAWWOOdqnHNNwGvABW2OOQ94woW8A/Qys/4eZhKRo4iPjeGeeVNJSYjlq08up1p7H3tqZ2kNg7JSfM3gZSFYDcw2s2wzSwHmAoPaHDMQ2Nnq613h5z7CzK4xswIzKygpKfEssIiE9M1I4q4vTWFLyX5ufmEVzmmymRfqm5oprKxjUFYPbRE459YBtwOvAC8BK4DmYzzXg865fOdcfk5OThemFJHDOWVEH248azQLV37IH5bs8DtOj7S7rBbnYFDvntsiwDn3sHNumnPuNKAM2NjmkN18tJWQF35ORALgq6eP4IzROfz4z2tZtavC7zg9zs6yWgAGZ/fgQmBmueE/BxMaH1jQ5pCFwOXhu4dmAhXOuT1eZhKRjouJMe686ESy0xK44Y/vUdd4TI16OYwdpTVAD28RAM+b2Vrgz8D1zrlyM7vOzK4Lv/43YAuwCfgd8DWP84hIJ/VOTeAXX5jM5pJqfrZovd9xepRdpTUkxMX4OpkMPN6Yxjk3u53n7m/1dwdc72UGETl+s0b24apZQ3n0rW2cOTaX2SdorK4r7CitIa93su87xWlmsYh0yE1nj2Fkbhrfe/Z9Kmoa/Y7TI+wsq2Gwz7eOggqBiHRQUnwsv7roRPbur+em59/XLaVdYGdpre/jA6BCICKdMDEvk5vOHsNLawq577XNfseJaBW1jVTUNqpFICKR5yuzh/HZyQO44+UNvLZREzyP1c4Ddwz5PJkMVAhEpJPMjNsvnMjovul886n32LGvxu9IEelQIVCLQEQiUEpCHA9cNg2Aa35fQE2D1iPqrJ1lKgQiEuGGZKdy15emsLGoiu89q8HjztpRWkOvlHgykvzbh+AAFQIROWanj8rhprPH8NdVe7h3sQaPOyModwyBCoGIHKdrThvOuZMH8ItXNvCv9UV+x4kYoeWn/R8oBhUCETlOocHjSYzrn8G3nlrBhkJtZnM0LS2OXWW1gRgfABUCEekCyQmx/O7yfJITYrnq0XcpqqzzO1KgFVXV0dDcoq4hEelZBvRK5pErT6K8tpEvP7ZUO5sdwc7S8PLTahGISE8zYWAm98ybyvrCKq5fsJym5ha/IwVSkOYQgAqBiHSxM0bn8uPzJrB4Qwn/9eJq3Vbajh2lNZjBwF7BGCz2dBlqEYlOl8wYzIfltdz96ib6ZSZxwydH+R0pUHaW1dA/I4mEuGD8Lq5CICKeuPGsURRW1vHrf3xAv4wkLp4+2O9IgRG6dTQY3UKgriER8YiZ8dMLJnL6qBx++OJqzTFoZYcKgYhEi/jYGO6dN5Vx/TP4xoL32FikOQYVNY0UVdYzMjfN7ygHqRCIiKdSE+P43eX5pCTG8ZXHCyirbvA7kq82hIvhmH7pPic5RIVARDzXLzOJBy+bRmFlHV99chmNUXxb6frCSgDG9MvwOckhKgQi0i2mDO7Nzy6YyDtbSrn1z2v8juOb9YVV9EqJp29Got9RDtJdQyLSbS6YmseGwioeeH0LY/plcOnMIX5H6nbr91Qyum86ZuZ3lIPUIhCRbvX9s8cwZ3QOP1q4hne27PM7TrdqaXFsKKxibP/gdAuBCoGIdLPYGOM3F09hcHYKX3ty+cHlFqLB7vJaqhuaGR2ggWJQIRARH2Qmx/PQ5fk0Nrcw/4mCqFmgbt2eAwPFKgQiIgzPSePuS6aysaiKb/9xBS0tPX9NogN7NYzqq0IgIgKEtrr8r/8Yxytri/jFKxv8juO59YVVDMlOITUxWPfpBCuNiESdq2YN5YPiKu5dvJkT+qbxuSl5fkfyzPrC0B1DQaMWgYj4ysy49dwJzBiWxU3Pr2LFznK/I3mirrGZrXurGROwO4ZAhUBEAiAhLob7L51GTloi1z+5vEcuQ7GpeD8tLngDxaBCICIB0Ts1gfsunUpJVT3ffqbnDR4H9Y4h8LgQmNm3zWyNma02s6fMLKnN64PN7FUze8/M3jezuV7mEZFgm5TXi//57DgWbyjhnlc3+R2nS20orCIpPoYh2al+R/kYzwqBmQ0EvgnkO+cmALHAxW0O+y/gGefclPBr93qVR0Qiw7wZgzn/xAHc+Y+NvPFBid9xusz6wipG9U0nNiY4S0sc4HXXUByQbGZxQArwYZvXHXBg5CSznddFJMqYGbddMJFRuel8fcF7bN1b7XekLhHUO4bAw0LgnNsN/ALYAewBKpxzr7Q57EfApWa2C/gb8I32zmVm15hZgZkVlJT0nN8QRKR9KQlxPHRFPrExxtWPL6WittHvSMelpKqevfsbAnnHEHjbNdQbOA8YBgwAUs3s0jaHfQl4zDmXB8wFfm9mH8vknHvQOZfvnMvPycnxKrKIBMigrBTumzeVnaU1fH3BcpoieA+Dgm2lAEzOy/Q5Sfu87Br6JLDVOVfinGsEXgBOaXPM1cAzAM65fwNJQB8PM4lIBJkxPJufnD+BNz7Yy21/W+93nGP25qa9pCXGMXlQL7+jtMvLQrADmGlmKRZaePtMYF07x5wJYGZjCRUC9f2IyEFfPGkwV54ylEfe2so/1hb5HeeYvLVpLzOHZxEfG8w79r0cI1gCPAcsB1aFr/Wgmf2vmZ0bPuxGYL6ZrQSeAq50zvWsm4dF5LjdPHcM4wdk8L3nVlJYUed3nE7ZWVrDtn01zBoZ3M4OT8uTc+4W59wY59wE59xlzrl659z/OOcWhl9f65yb5Zyb7Jw7sZ3BZBEREuNiuetLU6hrbOHbf1xBcwRNNnt7814ATo3WQiAi0lVG5KRx67nj+feWfdz/2ma/43TYm5v2kZueyMjcNL+jHJYKgYhEjC/k53HOpP7c+feNLN5Q7Heco2ppcby9aS+njuwTqD2K21IhEJGIYWbcfuEkRvcNTTY7sH5PUK0vrGJfdUOgxwdAhUBEIkxqYhyPXHkSaYlxfPmxpRRVBnfw+K1NofEBFQIRkS7WLzOJh6/Mp6K2kasfX0pNQzD3PH5z015G5qbRLzPp6Af7SIVARCLS+AGZ3H3JFNZ+WMkNTwdv2er6pmbe3Voa6LuFDlAhEJGI9YkxfQ/ueXxHwPY8Xr69nNrG5sB3C4H2LBaRCHfVrKFsLtnPfYs3M7xPKl/IH+R3JAAee3sraYlxzBye5XeUo1KLQEQimpnxo3PHM2tkNv/5/1axZMs+vyOxfEcZL68pYv7s4aQnxfsd56hUCEQk4sXHxnDvJdMYnJXC/CcK2FRc5VsW5xy3L1pPn7QEvjJ7mG85OkOFQER6hMyUeB67ajoJcbFc8chSin26rXTxxhKWbC3lm2eeQGpiZPS+qxCISI8xKCuFR688ibKaBq56bCn767v3ttKWFsfPX9rA4KwULj5pcD8dcXYAAAmpSURBVLde+3ioEIhIjzIxL5N7LpnK+sKqbt/Q5k8rd7NuTyU3njWKhLjI+fEaOUlFRDrojDG5/Pi8CSzeUMJP/tp2GxRv7Cyt4UcL1zIpL5PPThrQLdfsKpHRgSUi0kmXzBjMlpL9PPTmVobnpHL5yUM9u1ZdYzNfe3I5Lc7x2y9NISYmuAvMtUeFQER6rJvnjmXbvmp+tHANg7NSmDM615Pr/O9f1rJqdwW/uzyfIdmpnlzDS+oaEpEeKzbG+M3FUxjdL4OvPbmcdzyYY/DC8l0sWLKD604fwafG9e3y83cHFQIR6dFSE+N4/KqTGNgrmSseebdL9zF4b0cZN7+wipnDs/juWaO67LzdTYVARHq83Iwknr5mJiNy0pj/RAEvrS487nPuKqth/hMF9M1I4t5504gL6Mb0HRG5yUVEOiE7LZGnrpnJhIGZXL9gOU+9u+OYz1VV18jVjxVQ39TCI1eeRFZqQhcm7X4qBCISNTKT4/n91TM4dWQfbn5hFT9btL5Ty1e3tDhW7Cznq39YzqaS/dw3b1qg9yLuKN01JCJRJS0xjoevyOeWhWu4/7XN7Cyt4Y4vTCIlof0fhw1NLby1aS9/W7WHVzcUs3d/A7Exxm2fm8CpJwR/iemOUCEQkagTFxvDT86fwNDsVG5btI4lW/dx3ekjmDdjCMkJsZTXNPDOllL+ua6Il9cUUlnXRHpSHHNG53LmmFxOH5VD7wjvDmrNnAvWrj5Hk5+f7woKCvyOISI9xLLtZfzq7xt5c9Ne+qQlkpueyLrCSpyD9MQ4PjW+L+dM6s+pI3MiatmItsxsmXMuv93XVAhERODdraXct3gTdY0tnDwim1NGZDMpr1dE//Bv7UiFQF1DIiLA9GFZTB823e8YvugZpU5ERI6ZCoGISJRTIRARiXIqBCIiUU6FQEQkyqkQiIhEORUCEZEop0IgIhLlIm5msZmVANvDX2YCFUf4e9vn4oG9nbxk63N05LW2z3U044E/+3QyY3flO/CcPsNg5YuEjEHPdzwZj/Rc0D7DIc65nHbP7pyL2Afw4JH+3vY5oOB4rtGR19o+19GMrf7sVMbuyqfPMJj5IiFj0PMdT8ajZA3UZ3ikR6R3Df35KH8/3OvHeo2OvNb2uY5mDHq+o13rSPQZHv06R3K09wU9Y9DzHe71jmQ82nOd4fVneFgR1zV0PMyswB1m0aWgCHrGoOeD4GcMej4Ifsag54PIyHhApLcIOutBvwN0QNAzBj0fBD9j0PNB8DMGPR9ERkYgyloEIiLycdHWIhARkTZUCEREopwKgYhIlFMhCDOz2WZ2v5k9ZGZv+52nPWYWY2b/Z2a/NbMr/M7TlpnNMbM3wp/jHL/ztMfMUs2swMzO8TtLe8xsbPjze87Mvup3nvaY2flm9jsz+6OZneV3nrbMbLiZPWxmz/md5YDwv7vHw5/bPL/ztNUjCoGZPWJmxWa2us3zZ5vZBjPbZGY/ONI5nHNvOOeuA/4CPB7EjMB5QB7QCOwKYD4H7AeSApoP4Cbgma7M1pUZnXPrwv8OLwJmBTTji865+cB1wBcDmG+Lc+7qrszVnk5mvQB4Lvy5net1tk7rzMy3oD6A04CpwOpWz8UCm4HhQAKwEhgHTCT0w771I7fV+54B0oOYEfgBcG34vc8FMF9M+H19gScDmO9TwMXAlcA5QfxvHH7PucAi4JKgZgy/75fA1ADn69L/R44z683AieFjFniZ61gePWLzeufc62Y2tM3T04FNzrktAGb2NHCec+6nQLvdAmY2GKhwzlUFMaOZ7QIawl82By1fK2VAYtDyhburUgn9j1lrZn9zzrUEKWP4PAuBhWb2V2BBV+XrqoxmZsDPgEXOueVBy9ddOpOVUAs5D1hBAHtiekQhOIyBwM5WX+8CZhzlPVcDj3qW6OM6m/EF4LdmNht43ctgYZ3KZ2YXAJ8GegF3exsN6GQ+59wPAczsSmBvVxaBI+jsZziHUDdCIvA3T5Md0tl/h98APglkmtlI59z9Xoaj859hNvB/wBQzuzlcMLrL4bLeBdxtZv/BsS9B4ZmeXAg6zTl3i98ZjsQ5V0OoWAWSc+4FQsUq0Jxzj/md4XCcc4uBxT7HOCLn3F2EfrAFknNuH6Hxi8BwzlUDV/md43AC10TpQruBQa2+zgs/FyRBz6h8x08Zj1/Q87UWSVkP6smFYClwgpkNM7MEQoOEC33O1FbQMyrf8VPG4xf0fK1FUtZD/B6t7qLR+6eAPRy6rfLq8PNzgY2ERvF/qIzKp4zBzhj0fJGa9WgPLTonIhLlenLXkIiIdIAKgYhIlFMhEBGJcioEIiJRToVARCTKqRCIiEQ5FQLpEcxsfzdfr0v2rLDQHg4VZrbCzNab2S868J7zzWxcV1xfBFQIRNplZkdch8s5d0oXXu4N59yJwBTgHDM72j4E5xNaQVWkS6gQSI9lZiPM7CUzW2ahndPGhJ//rJktMbP3zOwfZtY3/PyPzOz3ZvYW8Pvw14+Y2WIz22Jm32x17v3hP+eEX38u/Bv9k+FlmjGzueHnlpnZXWb2lyPldc7VElqmeGD4/fPNbKmZrTSz580sxcxOIbRfwR3hVsSIw32fIh2lQiA92YPAN5xz04DvAveGn38TmOmcmwI8DXy/1XvGAZ90zn0p/PUYQktrTwduMbP4dq4zBbgh/N7hwCwzSwIeAD4Tvn7O0cKaWW/gBA4tMf6Cc+4k59xkYB2hJQzeJrR2zfeccyc65zYf4fsU6RAtQy09kpmlAacAz4Z/QYdDm+XkAX80s/6EdpHa2uqtC8O/mR/wV+dcPVBvZsWEdl9ruw3nu865XeHrrgCGEtqyc4tz7sC5nwKuOUzc2Wa2klAR+LVzrjD8/AQz+wmh/R3SgJc7+X2KdIgKgfRUMUB5uO+9rd8CdzrnFoY3gvlRq9eq2xxb3+rvzbT//0xHjjmSN5xz55jZMOAdM3vGObcCeAw43zm3MryZzpx23nuk71OkQ9Q1JD2Sc64S2GpmX4DQ9opmNjn8ciaH1oi/wqMIG4DhrbYyPOom7+HWw8+Am8JPpQN7wt1R81odWhV+7Wjfp0iHqBBIT5FiZrtaPb5D6Ifn1eFulzWE9o6FUAvgWTNbBuz1Iky4e+lrwEvh61QBFR146/3AaeEC8t/AEuAtYH2rY54Gvhce7B7B4b9PkQ7RMtQiHjGzNOfc/vBdRPcAHzjnfuV3LpG21CIQ8c788ODxGkLdUQ/4nEekXWoRiIhEObUIRESinAqBiEiUUyEQEYlyKgQiIlFOhUBEJMqpEIiIRLn/D8jNCpXhAOGjAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"vrtOeXiSqEov","executionInfo":{"status":"ok","timestamp":1604632533516,"user_tz":-420,"elapsed":582216,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Create a function to carry out the language model training schedule.\n","def train_language_model(model):\n","  # Choose some of the learning rates in reference to the graph above\n","\n","  # train the model with 1 epoch and 0.01 learning rate\n","  learn.fit_one_cycle(1, 1e-2)\n","  \n","  # Freeze all other than the last two parameter group and train the model again with 1 epoch\n","  # using different learning rate \n","  model.freeze_to(-2)\n","  model.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))\n","  \n","  # Unfreeze one more layer (freeze other than the last three) and train again with 1 epoch\n","  # using different learning rate \n","  model.freeze_to(-3)\n","  model.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))\n","\n","  # Unfreeze all of the layer (use the whole model)\n","  model.unfreeze()  \n","  # Train again for the last time with 5 epochs and 0.001 learning rate\n","  model.fit_one_cycle(5, 1e-3)  \n","  \n","  #save the language encoder into our file to be used later\n","  model.save_encoder(home_directory+language_directory+'/language_model-new')"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQqJoUz8qH5n","executionInfo":{"status":"ok","timestamp":1604634148311,"user_tz":-420,"elapsed":2196986,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"fc55b4b7-94d2-4a87-be29-f260d4aa37c5","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["train_language_model(learn)"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>6.964894</td>\n","      <td>6.601065</td>\n","      <td>0.075308</td>\n","      <td>02:57</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>6.609992</td>\n","      <td>6.344227</td>\n","      <td>0.091295</td>\n","      <td>03:04</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>6.402811</td>\n","      <td>6.214586</td>\n","      <td>0.099026</td>\n","      <td>03:19</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>6.237101</td>\n","      <td>6.187042</td>\n","      <td>0.100938</td>\n","      <td>03:31</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>6.176855</td>\n","      <td>6.098516</td>\n","      <td>0.107044</td>\n","      <td>03:29</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>6.057902</td>\n","      <td>6.005164</td>\n","      <td>0.115519</td>\n","      <td>03:30</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>5.949067</td>\n","      <td>5.964550</td>\n","      <td>0.119013</td>\n","      <td>03:29</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>5.896405</td>\n","      <td>5.955723</td>\n","      <td>0.119803</td>\n","      <td>03:29</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Bnz-7B5IRZwI"},"source":[""]},{"cell_type":"code","metadata":{"id":"0xuRCstBqKMH","executionInfo":{"status":"ok","timestamp":1604635474714,"user_tz":-420,"elapsed":2977,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["def initalise_classifier(input_df):\n","  #Construct a data loader for the abstract classifier.\n","  d_class = TextDataLoaders.from_df(input_df, text_col='Words', label_col='Label', valid_col='test')\n","\n","  #Decalre a new model, also based on a Long-Short Term Memory to predict the abstract class.\n","  model = text_classifier_learner(dls = d_class, arch = AWD_LSTM, drop_mult = 0.5,  metrics=accuracy)\n","  #Load our previously saved encoder on top of our new model, to transfer the learning to the new model.\n","  model = model.load_encoder(home_directory+language_directory+'/language_model-new')\n","\n","  return model"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"95w0NXAYzWFI","executionInfo":{"status":"ok","timestamp":1604635535307,"user_tz":-420,"elapsed":62384,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"9cacb952-f006-4523-e015-a9eab363c994","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["#Construct the new model\n","learn = initalise_classifier(df)"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"32-qx23jy_Ag","executionInfo":{"status":"ok","timestamp":1604635546170,"user_tz":-420,"elapsed":71778,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"797d80d2-008a-43f1-f298-10307c8cae9d","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["#Use the lr_find method to select the best learning rate for the one-cycle_fit method.\n","best_lr = learn.lr_find()"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"pjSwc7tsqMQw","executionInfo":{"status":"ok","timestamp":1604635546173,"user_tz":-420,"elapsed":70372,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Create a function to carry out the classifier training schedule.\n","def train_classifier_model(model):\n","  # Choose some of the learning rates in reference to the graph above  \n","\n","  # train the model with 1 epoch and 0.01 learning rate\n","  model.fit_one_cycle(1, 1e-2)\n","\n","  # Freeze all other than the last two parameter group and train the model again with 1 epoch\n","  # using different learning rate \n","  model.freeze_to(-2)\n","  model.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))\n","\n","  # Unfreeze one more layer (freeze other than the last three) and train again with 1 epoch\n","  # using different learning rate\n","  model.freeze_to(-3)\n","  model.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))\n","\n","  # Unfreeze all of the layer (use the whole model)\n","  model.unfreeze()\n","  # Train again for the last time with 2 epochs\n","  model.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))\n","\n","  # return trained model\n","  return model"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHnohiFpy8-B","executionInfo":{"status":"ok","timestamp":1604635945274,"user_tz":-420,"elapsed":466647,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"f25219ba-36ed-45ba-a987-38f4835f41a2","colab":{"base_uri":"https://localhost:8080/","height":288}},"source":["#Train the classifier\n","learn = train_classifier_model(learn)"],"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.982685</td>\n","      <td>1.554317</td>\n","      <td>0.560963</td>\n","      <td>00:51</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.712337</td>\n","      <td>1.492822</td>\n","      <td>0.561298</td>\n","      <td>00:55</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.519971</td>\n","      <td>1.471281</td>\n","      <td>0.570497</td>\n","      <td>01:22</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.408677</td>\n","      <td>1.455153</td>\n","      <td>0.569828</td>\n","      <td>01:44</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>1.344518</td>\n","      <td>1.452804</td>\n","      <td>0.570664</td>\n","      <td>01:44</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"14StbhM1qQJy","executionInfo":{"status":"ok","timestamp":1604635955422,"user_tz":-420,"elapsed":474339,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Load in the test data into a dataframe.\n","df_test = test_df.copy()\n","\n","#Construct a data loader with the test data.\n","d_test = learn.dls.test_dl(df_test, reorder=True, with_labels=False)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmzhhYyiqQ5c","executionInfo":{"status":"ok","timestamp":1604635969192,"user_tz":-420,"elapsed":487102,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}},"outputId":"6c322070-9164-4752-a6f2-900394b3ed0a","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["#get the prediction for our test data \n","#(the probability results for all of the labels and the label with the maximum probability)\n","preds, _, classes = learn.get_preds(dl=d_test, reorder=True, with_decoded=True)"],"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Ye6aaptTqUNx","executionInfo":{"status":"ok","timestamp":1604635969600,"user_tz":-420,"elapsed":485372,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#create new column called 'label' that store the predicted label values\n","df_test['label']=[learn.dls.vocab[1][int(x)] for x in classes]\n","#create new column called 'test_id' that stores the index\n","df_test['test_id'] = df_test.index + 1"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLt7x2cEqV9V","executionInfo":{"status":"ok","timestamp":1604635974630,"user_tz":-420,"elapsed":5021,"user":{"displayName":"Stephanie Liem","photoUrl":"","userId":"08009833276090851843"}}},"source":["#Export the current classifier model\n","learn.export(home_directory+model_directory+'/final_model-444.pkl')\n","\n","#Export the predictions\n","df_test[['test_id','label']].to_csv(home_directory+output_directory+'/pred_labels-444.csv', index=False)"],"execution_count":33,"outputs":[]}]}